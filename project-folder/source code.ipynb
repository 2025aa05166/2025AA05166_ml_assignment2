{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub xgboost scikit-learn pandas numpy\n",
        "\n",
        "# -----------------------\n",
        "# Imports\n",
        "# -----------------------\n",
        "import os\n",
        "import pickle\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, matthews_corrcoef, roc_auc_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "# -----------------------\n",
        "# Download Dataset\n",
        "# -----------------------\n",
        "dataset_path = kagglehub.dataset_download(\n",
        "    \"johnsmith88/heart-disease-dataset\"\n",
        ")\n",
        "df = pd.read_csv(os.path.join(dataset_path, \"heart.csv\"))\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "\n",
        "TARGET_COL = \"target\"\n",
        "X = df.drop(TARGET_COL, axis=1)\n",
        "y = df[TARGET_COL]\n",
        "\n",
        "# -----------------------\n",
        "# Train / Test Split\n",
        "# -----------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# Save TRAIN & TEST CSV\n",
        "# -----------------------\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "train_df = X_train.copy()\n",
        "train_df[TARGET_COL] = y_train\n",
        "train_df.to_csv(\"data/train.csv\", index=False)\n",
        "\n",
        "test_df = X_test.copy()\n",
        "test_df[TARGET_COL] = y_test\n",
        "test_df.to_csv(\"data/test.csv\", index=False)\n",
        "\n",
        "print(\"âœ… train.csv and test.csv saved\")\n",
        "\n",
        "# -----------------------\n",
        "# Preprocessing\n",
        "# -----------------------\n",
        "categorical_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(exclude=[\"object\"]).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numerical_cols),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -----------------------\n",
        "# Models\n",
        "# -----------------------\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"Naive Bayes\": GaussianNB(),\n",
        "    \"Random Forest (Ensemble)\": RandomForestClassifier(\n",
        "        n_estimators=200, random_state=42\n",
        "    ),\n",
        "    \"XGBoost (Ensemble)\": XGBClassifier(\n",
        "        eval_metric=\"logloss\", random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "evaluation_results = {}\n",
        "\n",
        "# -----------------------\n",
        "# Train, Evaluate & Save\n",
        "# -----------------------\n",
        "for name, clf in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "\n",
        "    pipeline = Pipeline(steps=[\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", clf)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    y_prob = (\n",
        "        pipeline.predict_proba(X_test)[:, 1]\n",
        "        if hasattr(pipeline, \"predict_proba\")\n",
        "        else None\n",
        "    )\n",
        "\n",
        "    evaluation_results[name] = {\n",
        "        \"metrics\": {\n",
        "            \"accuracy\": accuracy_score(y_test, y_pred),\n",
        "            \"precision\": precision_score(y_test, y_pred),\n",
        "            \"recall\": recall_score(y_test, y_pred),\n",
        "            \"f1\": f1_score(y_test, y_pred),\n",
        "            \"mcc\": matthews_corrcoef(y_test, y_pred),\n",
        "            \"auc\": roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
        "        },\n",
        "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
        "        \"classification_report\": classification_report(y_test, y_pred)\n",
        "    }\n",
        "\n",
        "    file_name = name.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
        "    with open(f\"model/{file_name}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(pipeline, f)\n",
        "\n",
        "print(\"âœ… All model .pkl files saved\")\n",
        "\n",
        "# -----------------------\n",
        "# Save evaluation_results.pkl\n",
        "# -----------------------\n",
        "with open(\"model/evaluation_results.pkl\", \"wb\") as f:\n",
        "    pickle.dump(evaluation_results, f)\n",
        "\n",
        "print(\"âœ… evaluation_results.pkl saved\")\n",
        "\n",
        "# -----------------------\n",
        "# CREATE MODEL COMPARISON TABLE\n",
        "# -----------------------\n",
        "\n",
        "comparison_rows = []\n",
        "\n",
        "for model_name, results in evaluation_results.items():\n",
        "    m = results[\"metrics\"]\n",
        "    comparison_rows.append({\n",
        "        \"ML Model Name\": model_name,\n",
        "        \"Accuracy\": round(m[\"accuracy\"], 3),\n",
        "        \"AUC\": round(m[\"auc\"], 3) if m[\"auc\"] is not None else \"N/A\",\n",
        "        \"Precision\": round(m[\"precision\"], 3),\n",
        "        \"Recall\": round(m[\"recall\"], 3),\n",
        "        \"F1\": round(m[\"f1\"], 3),\n",
        "        \"MCC\": round(m[\"mcc\"], 3)\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_rows)\n",
        "\n",
        "print(\"\\nðŸ“Š MODEL COMPARISON TABLE\")\n",
        "print(comparison_df)\n",
        "comparison_df.to_csv(\"model/model_comparison.csv\", index=False)\n",
        "print(\"\\nâœ… model_comparison.csv saved\")\n",
        "\n",
        "\n",
        "# -----------------------\n",
        "# ZIP EVERYTHING\n",
        "# -----------------------\n",
        "zip_name = \"ml_assignment_assets\"\n",
        "shutil.make_archive(zip_name, \"zip\", \".\")\n",
        "\n",
        "# -----------------------\n",
        "# Download ZIP\n",
        "# -----------------------\n",
        "files.download(f\"{zip_name}.zip\")\n",
        "\n",
        "print(\"\\nðŸ“¦ ml_assignment_assets.zip downloaded successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "yjODNDqHQRnJ",
        "outputId": "6b2f56e5-f61d-49c3-efba-0b9b557752ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (26.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.29.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2026.1.4)\n",
            "Using Colab cache for faster access to the 'heart-disease-dataset' dataset.\n",
            "Dataset shape: (1025, 14)\n",
            "âœ… train.csv and test.csv saved\n",
            "Training Logistic Regression...\n",
            "Training Decision Tree...\n",
            "Training KNN...\n",
            "Training Naive Bayes...\n",
            "Training Random Forest (Ensemble)...\n",
            "Training XGBoost (Ensemble)...\n",
            "âœ… All model .pkl files saved\n",
            "âœ… evaluation_results.pkl saved\n",
            "\n",
            "ðŸ“Š MODEL COMPARISON TABLE\n",
            "              ML Model Name  Accuracy    AUC  Precision  Recall     F1    MCC\n",
            "0       Logistic Regression     0.810  0.930      0.762   0.914  0.831  0.631\n",
            "1             Decision Tree     0.985  0.986      1.000   0.971  0.986  0.971\n",
            "2                       KNN     0.863  0.963      0.874   0.857  0.865  0.727\n",
            "3               Naive Bayes     0.829  0.904      0.807   0.876  0.840  0.660\n",
            "4  Random Forest (Ensemble)     1.000  1.000      1.000   1.000  1.000  1.000\n",
            "5        XGBoost (Ensemble)     1.000  1.000      1.000   1.000  1.000  1.000\n",
            "\n",
            "âœ… model_comparison.csv saved\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2064d6e2-d252-401f-8772-46f0e21330e0\", \"ml_assignment_assets.zip\", 7603794)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“¦ ml_assignment_assets.zip downloaded successfully!\n"
          ]
        }
      ]
    }
  ]
}